Matthew McAlarney - memcalarney
Alison McNicholas - almcnicholas

Part 2:

Overview of how we used locks and condition variables in our program:
	When tackling this problem, we used the Hilli Steele Approach with a barrier created by conditional variables. We used multiple threads in our solution which lead us to utilize locks and barriers. We use mutex locks to indicate when a thread could write to the threadcounter or access other information. This mechnaism ensures correctness, and helped us prevent data (threadcounter value) from overwriting each other or a thread from trying to write to the threadcounter at the same time as another thread and cause a segmentation fault. We then use a barrier containing a condition variable to allow our program to block a group of threads (through pthread_cond_wait function) until all of the threads have arrived at the critical section. In doing so we could ensure that all of the threads waited for each other before moving on to compute the next depth/level of computation for the Hillis Steele algorithm of the prefix sum. The last thread to arrive in the critical section meets the condition that the maximum number of threads have arrived, resulting in the p_thread_broadcast function getting called and allowing all threads to move to compute the next depth/level of computation. As a result, we avoid deadlocks between threads by making sure that the last thread to arrive in the critical section is able to unblock all of the previous threads that arrived earler (no two threads are waiting on each other to perform an operating or signal in our case). Our use of condition variables to create the barrier placed before each subsequent level of computation of the Hillis Steele algorithm helps the program prevent race conditions and finishedarray entry miscalculations, which are a result of not all of the threads being present at the subsequent level of computation to concurrently compute the sums of entries specified by argument indexes. 
	
Detailed Explanation of our program design, lock and condition varaible use, and how we maximized thread concurrency:
	When running our solution against the test cases in part 1, it starts by checking if there are 4 input arguments. This will tell us if we have enough input data to run our program correctly. Additionally, we check if there are fewer than two numbers for the prefix sum. We must check this condition to ensure we are able to compute the prefix sum. If any of these two conditions are false, we return an EXIT_FAILURE, if not we continue the program. 
	If there are 4 input arguments, then we initialize a few of the variables that we will be using later in the program (filename, n, and numthreads). Then, we set aside memory and read in all of the contents of the filename through a helper function read_input_vector. Additionally, we will initialize the mutex lock, and use its default attributes through passing the global lock variavle (lock) and NULL. We use a mutex lock because it conceptually enforces limits on access to resources when there are a number of threads in contention for those resources. As an example, in our program, we enforce mutual exclusion in our critical section containing the barrier to make sure that only one thread is accessing and writing to the threadcounter at a time (our mechanism of correctness). Going back to our main function, another check that we make is if the conditional variable cond 1 was initialized correctly (checking to make sure the initialization function does not return 0). If the condition variable initialization function does not return 0, it returns an error through perror() stating that there was an error initializing the condition variable (cond 1). 
	After initializing and assigning global and local variables, we create each thread from the threadlist using a for loop. We send each thread to the calculate prefix sum function with a void pointer to a set of arguments defined inside of a struct named args_t (specifically, each thread has access to its own set of arguments consisting of a unique startind index and copy of the globally defined totally number of threads). The use of the args_t struct allows all of the threads to have access to a unique starting index in the finishedarray and total number of threads. Within the for loop where we call pthread_create() to create each thread, we start by allocating memory on the heap for a variable of tyoe struct args_t. We then set the numth to the number of threads and the start index field to the current value of x in the for loop iteration. When creating each thread using pthread_create(), we reference a specific index in the threadlist. Within a call to pthread_create(), we also send in NULL for default attributes (attr), the function calculateprefixsum, and the void pointer to the arguments defined in our variable of type struct args_t.
	The calculate prefix sum function is not locked with a mutex lock so all of the threads can enter at a similar time and allow for concurrent computations to occur. We start by unpacking the args_struct variable casted from the parameter void pointer, and we initialize local variables start and numth using the start and numth fields of the args_s struct. We then fill the first level of computation of the finished array with the values of global array input according to the logic of the Hillis Steele algorithm. Next, we iterate over each row of the finished array, which is conceptually equivalent to iterating over each level of computation of the Hillis Steele Algorithm. We iterate a counter variable i to log2(n), which is because the prefix sum of the input array will be complete when i is equal to log2(n). During each iteration, we have the thread call the barrier function and wait at this barrier until all of the threads have arrived. As a result, all threads can concurrently enter the next level of computation of the Hillis Steele algorithm. 
	Inside the barrier function, we use a mutex lock to lock the thread counter resource so that the outside threads cannot write to it at the same time as the thread that has obtained the lock. We have this function to specifically avoid deadlocks, as well as ensure correctnees/mutual exclusion. We found when creating the Hillis Steele algorithm that without the barrier placed before each level of computation, multiple threads would access the same data, causing both operations to cease. So, when the current thread enters, it increments the thread counter variable to reflect the current number of threads that have entered this section, the “critical section” of the algorithm. If not all of the threads have arrived, then the current thread entering must wait on the conditional variable cond1 and release the mutex lock so that other threads can enter the critical section. When this happens, the mutex is unlocked so the other threads can increment the thread counter. We do this here to ensure that the program can continue to run and not end up waiting for a thread to continue when it cannot. Then, if the current thread is the last thread to enter, we set the thread counter to 0 to reflect that all of the threads have entered. We then broadcast with the condition variable, cond1, that all threads currently waiting or being blocked by cond1 should become unblocked, and that we should allow all threads to continue their execution into the next level computation of the Hillis Steele algorithm. Additionally, at the end of the barrier, we unlock the mutex lock so all of the threads can continue execution. 
	Then, back to the calculateprefixsum function, our inner for loop iterates over each column of the finishedarray where each entry increments by the number of threads. This type of incrementation ensures that all threads acccess their indexes assigned in the thread creation loop in the main function without overwriting each other. Also, it makes sure that all values in the column indexes are accounted for in the event of needing to drop down a number to the left. To do this, we check if the current index is less than 2^i to the right of the start index. If true, we drop down the entry from the current level of computation, or the row, to the next level. In not, we set the value at the index located exactly one row below to the sum of the current entry and the entry located 2^i to the left on the current level of computation. Finally, we return NULL. In summary, we assign each thread at least one column index in the finished array, which means that the workload of completing the Hillis Steele algorithm involves assigning each thread at least one sum to compute assuming there are at least 2 levels of the finishedarray. In addition, all threads compute their sums concurrently on a given level of computation in the Hillis Steele algorithm due to the mechanism of our barrier, which forces all threads to wait for each other to arrive at the critical section before entering the next depth of the Hillis Steele algorithm together. The concurrent computation of sums on each level of the algorithm helps optimize the performance time of the prefix sum calculation for a given input array. Also, the fact that each thread has access to its own start index and copy of the number of threads reduces the number of reads to the global variable numthreads, which also helps improve the performane time of the prefix sum calculation.
	Back to main, when creating these threads we store the returned value to a result variable. We can then check if the thread could not be created, and if so, we return an error. After this, we iterate through the threadlist and join each thread. This allows the main function to continue execution once all threads are finished with their individual executions of the Hillis Steele Algorithm. When using the pthread_join function we use the default attributes. Next, we destroy the mutex lock since all of the threads created to compute parts of the prefix sum calculation have terminated. We then print the prefix sum by calling a helper function. 
	In the print prefix sum function, we first obtain the last row of the finishedarray, since this is where the finished prefix sum calculation is stored. Then, for each entry in the last row, we print the entry. We access the corresponding entry by referencing a quantity containing the current row multiplied by the length of that row and then adding the number of entries into the current level of computation. When finished, we return a NULL value. 
	Next, back to the main function, we destroy the condition variable because we have no need for it anymore. If there is an error in this process we return that this is an error and exit(2). Finally, we free the input and the finished array from the heap and then call EXIT_SUCCESS. 
